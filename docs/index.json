[{"authors":null,"categories":null,"content":"个人简介, 控制在600-800个英文字符之内\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"4e73f707a3c1da0c5d8d165361161c7b","permalink":"/authors/19_ruize/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/19_ruize/","section":"authors","summary":"个人简介, 控制在600-800个英文字符之内","tags":null,"title":"Ruize Xu","type":"authors"},{"authors":null,"categories":null,"content":"Guangyao is a Ph.D. Candidate at GeWu-Lab, Gaoling School of Artificial Intelligence, Renmin University of China, advised by Prof. Di Hu. He got his master degree at China Agricultural University in 2020 and got into GeWu-Lab since then. His recently research interests include audio-visual learning and scene understanding. And he hopes to brave the no-man\u0026rsquo;s land on the road of scientific research and make warm artificial intelligence research! People who are interested in my research domain are very welcome and do not hesitate to contact me actively. For more information, please visit his personal homepage. Valar Morghulis！\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"537de72d4cb178cea6fbf2b2a92ea589","permalink":"/authors/20_guangyao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/20_guangyao/","section":"authors","summary":"Guangyao is a Ph.D. Candidate at GeWu-Lab, Gaoling School of Artificial Intelligence, Renmin University of China, advised by Prof. Di Hu. He got his master degree at China Agricultural University in 2020 and got into GeWu-Lab since then. His recently research interests include audio-visual learning and scene understanding. And he hopes to brave the no-man\u0026rsquo;s land on the road of scientific research and make warm artificial intelligence research! People who","tags":null,"title":"Guangyao Li","type":"authors"},{"authors":null,"categories":null,"content":"Xiaokang is a master student in GeWu-Lab at Renmin University of China, advised by Prof. Di Hu. He got his undergraduate degree at School of Information, Renmin University of China in 2020 and got into GeWu-Lab since then. He is interested in multi-modal learning and perception, and optimization mechanism design. And he is also devoted to help these visually impaired with AI in both technology and practice.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"22debf3f166bda4bfb28c8317489f918","permalink":"/authors/20_xiaokang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/20_xiaokang/","section":"authors","summary":"Xiaokang is a master student in GeWu-Lab at Renmin University of China, advised by Prof. Di Hu. He got his undergraduate degree at School of Information, Renmin University of China in 2020 and got into GeWu-Lab since then. He is interested in multi-modal learning and perception, and optimization mechanism design. And he is also devoted to help these visually impaired with AI in both technology and practice.","tags":null,"title":"Xiaokang Peng","type":"authors"},{"authors":null,"categories":null,"content":"个人简介, 控制在600-800个英文字符之内\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"55a49bcd8ae300a0362a45302ca97c26","permalink":"/authors/20_xuemin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/20_xuemin/","section":"authors","summary":"个人简介, 控制在600-800个英文字符之内","tags":null,"title":"Xuemin Liu","type":"authors"},{"authors":null,"categories":null,"content":"Yixin is a master student at Gaoling School of Artificial Intelligence, Renmin University of China. His main research topics are Multi-modal Scene Perception and Self-surpervised Representation Learning. Now he is working on video understanding and speaker diarization task for complex speech scenario. He is also interested in Internet finance, and has got his Bachelor of Finance in Renmin University of China besides the Computer Science degree.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"033ae9c233d8ca15172e0f0eb482735e","permalink":"/authors/20_yixin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/20_yixin/","section":"authors","summary":"Yixin is a master student at Gaoling School of Artificial Intelligence, Renmin University of China. His main research topics are Multi-modal Scene Perception and Self-surpervised Representation Learning. Now he is working on video understanding and speaker diarization task for complex speech scenario. He is also interested in Internet finance, and has got his Bachelor of Finance in Renmin University of China besides the Computer Science degree.","tags":null,"title":"Yixin Xu","type":"authors"},{"authors":null,"categories":null,"content":"个人简介, 控制在600-800个英文字符之内\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"207e4d0624d5542d0968bc001ed378e1","permalink":"/authors/20_zhaoyang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/20_zhaoyang/","section":"authors","summary":"个人简介, 控制在600-800个英文字符之内","tags":null,"title":"Zhaoyang Yu","type":"authors"},{"authors":null,"categories":null,"content":"Rui is interested in computer vision and machine learning, and has done some research on video representation learning and joint audio-visual learning. During his undergraduate he works with Prof. Di Hu. Now Rui is a Ph.D. student in Multi-Media Lab at The Chinese University of Hong Kong, supervised by Prof. Dahua Lin.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"9434b9dca31f1f23a676f2b869e0c881","permalink":"/authors/21_ruiqian/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/21_ruiqian/","section":"authors","summary":"Rui is interested in computer vision and machine learning, and has done some research on video representation learning and joint audio-visual learning. During his undergraduate he works with Prof. Di Hu. Now Rui is a Ph.D. student in Multi-Media Lab at The Chinese University of Hong Kong, supervised by Prof. Dahua Lin.","tags":null,"title":"Rui Qian","type":"authors"},{"authors":null,"categories":null,"content":"Yake is a PhD student at Gaoling School of Artificial Intelligence, Renmin University of China. She received her bachelor\u0026rsquo;s degree in Computer Science and Technology from University of Electronic Science and Technology of China in 2021. Now her research interests focus on the effective mechanism of multi-modal learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"57b1d4e29185f3870d53fc65c766173e","permalink":"/authors/21_yake/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/21_yake/","section":"authors","summary":"Yake is a PhD student at Gaoling School of Artificial Intelligence, Renmin University of China. She received her bachelor\u0026rsquo;s degree in Computer Science and Technology from University of Electronic Science and Technology of China in 2021. Now her research interests focus on the effective mechanism of multi-modal learning.","tags":null,"title":"Yake Wei","type":"authors"},{"authors":null,"categories":null,"content":"Andong Deng spent a wonderful year at GeWu Lab doing research about multimodal learning with Dr. Di Hu from 2021 to 2022. Now he is an upcoming PhD student in 2022 Fall at Center for Research in Computer Vision, University of Central Florida, advised by Dr. Chen Chen. His research interests include multi-modal learning, video understanding and 3D vision.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"c95476ad24cc214056b3d2c5e8c90f17","permalink":"/authors/22_andong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/22_andong/","section":"authors","summary":"Andong Deng spent a wonderful year at GeWu Lab doing research about multimodal learning with Dr. Di Hu from 2021 to 2022. Now he is an upcoming PhD student in 2022 Fall at Center for Research in Computer Vision, University of Central Florida, advised by Dr. Chen Chen. His research interests include multi-modal learning, video understanding and 3D vision.","tags":null,"title":"Andong Deng","type":"authors"},{"authors":null,"categories":null,"content":"个人简介, 控制在600-800个英文字符之内\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"85c72bc0c3493475079c83a6c1a67ab9","permalink":"/authors/22_jingxian/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/22_jingxian/","section":"authors","summary":"个人简介, 控制在600-800个英文字符之内","tags":null,"title":"Jingxian Lu","type":"authors"},{"authors":null,"categories":null,"content":"Wenke is an upcoming PhD student in 2022 Fall at Gaoling School of Artificial Intelligence, Renmin University of China, advised by Prof. Di Hu. He have also interned at Big Data Lab, Baidu, working with Dr. Xingjian Li and Dr. Dejing Dou. His research interests include cross-modal transfer learning and multi-modal learning and is currently focusing on the Embodied AI with multi-modal sensory information.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"a2791369e75b13b52139d9860293bdd5","permalink":"/authors/22_wenke/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/22_wenke/","section":"authors","summary":"Wenke is an upcoming PhD student in 2022 Fall at Gaoling School of Artificial Intelligence, Renmin University of China, advised by Prof. Di Hu. He have also interned at Big Data Lab, Baidu, working with Dr. Xingjian Li and Dr. Dejing Dou. His research interests include cross-modal transfer learning and multi-modal learning and is currently focusing on the Embodied AI with multi-modal sensory information.","tags":null,"title":"Wenke Xia","type":"authors"},{"authors":null,"categories":null,"content":"Wenxuan will start his Ph.D program in the GeWu-Lab, Gaoling School of Artificial Intelligence, Renmin University of China, in Sept. 2022. He has got his bachelor\u0026rsquo;s degree and master\u0026rsquo;s degree in Northwestern Polytechnical University and Xi\u0026rsquo;an Jiaotong University, respectively. Currently he has joined GeWu-Lab as a research assistant. His main research interests are egocentric scene understanding and multimodal learnng, aims to learning and understanding human action and perception. He is also interested in deep learning model design and neural architecture search.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"cd37724dba9b446f1c1307e40cd45632","permalink":"/authors/22_wenxuan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/22_wenxuan/","section":"authors","summary":"Wenxuan will start his Ph.D program in the GeWu-Lab, Gaoling School of Artificial Intelligence, Renmin University of China, in Sept. 2022. He has got his bachelor\u0026rsquo;s degree and master\u0026rsquo;s degree in Northwestern Polytechnical University and Xi\u0026rsquo;an Jiaotong University, respectively. Currently he has joined GeWu-Lab as a research assistant. His main research interests are egocentric scene understanding and multimodal learnng, aims to learning and understanding human action and perception. He is","tags":null,"title":"Wenxuan Hou","type":"authors"},{"authors":null,"categories":null,"content":"Xincheng Pang is a senior student in the School of Software, Northwestern Polytechnical University. He will join the GeWu-Lab for a master\u0026rsquo;s degree in 2022. His research interests focus on multi-modal machine learning and embodied AI.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"a389590984a0c3fb50de499f8df2d4c0","permalink":"/authors/22_xincheng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/22_xincheng/","section":"authors","summary":"Xincheng Pang is a senior student in the School of Software, Northwestern Polytechnical University. He will join the GeWu-Lab for a master\u0026rsquo;s degree in 2022. His research interests focus on multi-modal machine learning and embodied AI.","tags":null,"title":"Xincheng Pang","type":"authors"},{"authors":null,"categories":null,"content":"Zequn is a fourth-year undergraduate student of Beihang University. Zequn is about to graduate with his bachelor\u0026rsquo;s degree in 2022 and will work for Ph.D. He currently focuses on multi-view clustering with machine learning methods. And he is also interested in the theoretical comprehension and optimization of multimodal learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"d884fc3eb1e2b2382def5073cec5e105","permalink":"/authors/22_zequn/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/22_zequn/","section":"authors","summary":"Zequn is a fourth-year undergraduate student of Beihang University. Zequn is about to graduate with his bachelor\u0026rsquo;s degree in 2022 and will work for Ph.D. He currently focuses on multi-view clustering with machine learning methods. And he is also interested in the theoretical comprehension and optimization of multimodal learning.","tags":null,"title":"Zequn Yang","type":"authors"},{"authors":null,"categories":null,"content":"个人简介, 控制在600-800个英文字符之内\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"c29a63de0242659b43a43451fc077046","permalink":"/authors/23_ruoxuan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/23_ruoxuan/","section":"authors","summary":"个人简介, 控制在600-800个英文字符之内","tags":null,"title":"Ruoxuan Feng","type":"authors"},{"authors":["dihu"],"categories":null,"content":"Di Hu is tenure-track faculty at Gaoling School of Artificial Intelligence, Renmin University of China. Before that, he was previously a research scientist at Baidu Research. Di Hu obtained the Ph.D degree from Northwestern Polytechnical University in 2019, supervised by Xuelong Li. Currently, Di Hu is leading the GeWu Lab and exploring how to understand and interact with the world via the natural multimodal messages. He is an aficionado of cognitive neuroscience and has wrote one study note during his undergraduate. Inspired by what he learned from cognitive neuroscience, and what he observed and deliberated from the daily-life, he strongly convinced that the pervasive, free, natural multimodal messages can provide sufficient information for perceiving, learning and understanding environment, even the agent itself, which promisingly makes multimodal learning become one of the key to achieve machine intelligence.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Di Hu is tenure-track faculty at Gaoling School of Artificial Intelligence, Renmin University of China. Before that, he was previously a research scientist at Baidu Research. Di Hu obtained the Ph.D degree from Northwestern Polytechnical University in 2019, supervised by Xuelong Li. Currently, Di Hu is leading the GeWu Lab and exploring how to understand and interact with the world via the natural multimodal messages. He is an aficionado of","tags":null,"title":"Di Hu","type":"authors"},{"authors":["Rui Qian","Di Hu","Heinrich Dinkel","Mengyue Wu","Ning Xu","Weiyao Lin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"852b491b0dcadb44b8f099f931db74c4","permalink":"/publication/a-two-stage-framework-for-multiple-sound-source-localization/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/a-two-stage-framework-for-multiple-sound-source-localization/","section":"publication","summary":"","tags":null,"title":"A Two-Stage Framework for Multiple Sound-Source Localization","type":"publication"},{"authors":["Di Hu*","Lichao Mou*","Qingzhong Wang*","Junyu Gao","Yuansheng Hua","Dejing Dou","Xiao Xiang Zhu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b21459d2cd2aa98d5a771a396df3c29e","permalink":"/publication/ambient-sound-helps_-audiovisual-crowd-counting-in-extreme-conditions/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/ambient-sound-helps_-audiovisual-crowd-counting-in-extreme-conditions/","section":"publication","summary":"","tags":null,"title":"Ambient Sound Helps: Audiovisual Crowd Counting in Extreme Conditions","type":"publication"},{"authors":["Xiaokang Peng*","Yake Wei*","Andong Deng","Dong Wang","Di Hu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1cdda2159c4adeb4f31cb4e7f1a5ab8a","permalink":"/publication/balanced-multimodal-learning-via-on-the-fly-gradient-modulation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/balanced-multimodal-learning-via-on-the-fly-gradient-modulation/","section":"publication","summary":"","tags":null,"title":"Balanced Multimodal Learning via On-the-fly Gradient Modulation","type":"publication"},{"authors":["Di Hu","Yake Wei","Rui Qian","Weiyao Lin","Ruihua Song","Ji-Rong Wen"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"91e67073102678aec9799732ceef49f3","permalink":"/publication/class-aware-sounding-objects-localization-via-audiovisual-correspondence/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/class-aware-sounding-objects-localization-via-audiovisual-correspondence/","section":"publication","summary":"","tags":null,"title":"Class-aware Sounding Objects Localization via Audiovisual Correspondence","type":"publication"},{"authors":["Yapeng Tian*","Di Hu*","Chenliang Xu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c0d82a52007e4e9ab50a2cfafdc4ac17","permalink":"/publication/co-learn-sounding-object-visual-grounding-and-visually-indicated-sound-separation-in-a-cycle/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/co-learn-sounding-object-visual-grounding-and-visually-indicated-sound-separation-in-a-cycle/","section":"publication","summary":"","tags":null,"title":"Co-Learn Sounding Object Visual Grounding and Visually Indicated Sound Separation in A Cycle","type":"publication"},{"authors":["Di Hu","Xuhong Li","Lichao Mou","Pu Jin","Dong Chen","Liping Jing","Xiaoxiang Zhu","Dejing Dou"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c7688dd14aa743d0b927f94d97854f27","permalink":"/publication/cross-task-transfer-for-geotagged-audiovisual-aerial-scene-recognition/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/cross-task-transfer-for-geotagged-audiovisual-aerial-scene-recognition/","section":"publication","summary":"","tags":null,"title":"Cross-Task Transfer for Geotagged Audiovisual Aerial Scene Recognition","type":"publication"},{"authors":["Di Hu","Zheng Wang","Haoyi Xiong","Dong Wang","Feiping Nie","Dejing Dou"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ac02b15b850ff085e6c9ad497f3a130c","permalink":"/publication/curriculum-audiovisual-learning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/curriculum-audiovisual-learning/","section":"publication","summary":"","tags":null,"title":"Curriculum Audiovisual Learning","type":"publication"},{"authors":["Yapeng Tian","Di Hu*","Chenliang Xu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cd0308a1bfb55705c394057955f2375d","permalink":"/publication/cyclic-co-learning-of-sounding-object-visual-grounding-and-sound-separation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/cyclic-co-learning-of-sounding-object-visual-grounding-and-sound-separation/","section":"publication","summary":"","tags":null,"title":"Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation","type":"publication"},{"authors":["Di Hu","Feiping Nie","Xuelong Li"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"202776673a51788c119f1451c9e313c2","permalink":"/publication/deep-binary-reconstruction-for-cross-modal-hashing-journal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/deep-binary-reconstruction-for-cross-modal-hashing-journal/","section":"publication","summary":"","tags":null,"title":"Deep Binary Reconstruction for Cross-modal Hashing","type":"publication"},{"authors":["Di Hu","Feiping Nie","Xuelong Li"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"00f72a8fe1deeb265958a59b94c2cd33","permalink":"/publication/deep-binary-reconstruction-for-cross-modal-hashing/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/deep-binary-reconstruction-for-cross-modal-hashing/","section":"publication","summary":"","tags":null,"title":"Deep Binary Reconstruction for Cross-modal Hashing","type":"publication"},{"authors":["Di Hu","Feiping Nie","Xuelong Li"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f6c0a9a658cdceee78bd291860181d99","permalink":"/publication/deep-linear-discriminant-analysis-hashing-supplemental-material/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/deep-linear-discriminant-analysis-hashing-supplemental-material/","section":"publication","summary":"","tags":null,"title":"Deep Linear Discriminant Analysis Hashing Supplemental Material","type":"publication"},{"authors":["Di Hu","Feiping Nie","Xuelong Li"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d1466a6c42ba930502049d24243f8b62","permalink":"/publication/deep-multimodal-clustering-for-unsupervised-audiovisual-learning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/deep-multimodal-clustering-for-unsupervised-audiovisual-learning/","section":"publication","summary":"","tags":null,"title":"Deep Multimodal Clustering for Unsupervised Audiovisual Learning Representation","type":"publication"},{"authors":["Di Hu - Chengze Wang - Feiping Nie - Xuelong Li"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9e4cd76d6b972d54b50c190779f639a5","permalink":"/publication/dense-multimodal-fusion-for-hierarchically-joint-representation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/dense-multimodal-fusion-for-hierarchically-joint-representation/","section":"publication","summary":"","tags":null,"title":"Dense Multimodal Fusion for Hierarchically Joint Representation","type":"publication"},{"authors":["Di Hu","Feiping Nie","Xuelong Li"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4b1e10b4327cca00dfd58162571a2f8c","permalink":"/publication/discrete-spectral-hashing-for-efficient-similarity-retrieval/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/discrete-spectral-hashing-for-efficient-similarity-retrieval/","section":"publication","summary":"","tags":null,"title":"Discrete Spectral Hashing for Efficient Similarity Retrieval","type":"publication"},{"authors":["Di Hu","Rui Qian","Minyue Jiang","Xiao Tan","Shilei Wen","Errui Ding","Weiyao Lin","Dejing Dou"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d6953eeac03ee85322e85eece2eeeb84","permalink":"/publication/discriminative-sounding-objects-localization-via-self-supervised-audiovisual-matching/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/discriminative-sounding-objects-localization-via-self-supervised-audiovisual-matching/","section":"publication","summary":"","tags":null,"title":"Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching","type":"publication"},{"authors":["Di Hu*","Lichao Mou*","Qingzhong Wang*","Junyu Gao","Yuansheng Hua","Dejing Dou","Xiaoxiang Zhu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3016d01c7b86e792f8778f7aba6fc44d","permalink":"/publication/does-ambient-sound-help_-audiovisual-crowd-counting/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/does-ambient-sound-help_-audiovisual-crowd-counting/","section":"publication","summary":"","tags":null,"title":"Does Ambient Sound Help? - Audiovisual Crowd Counting","type":"publication"},{"authors":["Sijia Yang","Haoyi Xiong","Di Hu","Kaibo Xu","Licheng Wang","Peizhen Zhu","Zeyi Sun."],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ed52bf34eef1f16fc89a0fc5c32fa152","permalink":"/publication/generalising-combinatorial-discriminant-analysis-through-conditioning-truncated-rayleigh-flow/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/generalising-combinatorial-discriminant-analysis-through-conditioning-truncated-rayleigh-flow/","section":"publication","summary":"","tags":null,"title":"Generalising Combinatorial Discriminant Analysis through Conditioning Truncated Rayleigh Flow","type":"publication"},{"authors":["Di Hu","Zheng Wang","Haoyi Xiong","Dong Wang","Feiping Nie","Dejing Dou"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8fe03bbbdab04c3ee4ecc7e01ecd723c","permalink":"/publication/heterogeneous-scene-analysis-via-self-supervised-audiovisual-learning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/heterogeneous-scene-analysis-via-self-supervised-audiovisual-learning/","section":"publication","summary":"","tags":null,"title":"Heterogeneous Scene Analysis via Self-supervised Audiovisual Learning","type":"publication"},{"authors":["Xuelong Li","Di Hu","Xiaoqiang Lu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1850ab6a7473c571586aed28d796ac66","permalink":"/publication/image2song-song-retrieval-via-bridging-image-content-and-lyric-words/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/image2song-song-retrieval-via-bridging-image-content-and-lyric-words/","section":"publication","summary":"","tags":null,"title":"Image2song: Song Retrieval via Bridging Image Content and Lyric Words","type":"publication"},{"authors":["Xuelong Li","Di Hu","Feiping Nie"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"24881bb5f959ea9f061fb67469d72eb9","permalink":"/publication/large-graph-hashing-with-spectral-rotation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/large-graph-hashing-with-spectral-rotation/","section":"publication","summary":"","tags":null,"title":"Large Graph Hashing with Spectral Rotation","type":"publication"},{"authors":["Guangyao Li*","Yake Wei*","Yapeng Tian*","Chenliang Xu","Ji-Rong Wen","Di Hu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"125a97cdaa82fb5a0ec455cfd53c1b46","permalink":"/publication/learning-to-answer-questions-in-dynamic-audio-visual-scenarios/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/learning-to-answer-questions-in-dynamic-audio-visual-scenarios/","section":"publication","summary":"","tags":null,"title":"Learning to Answer Questions in Dynamic Audio-Visual Scenarios","type":"publication"},{"authors":["Di Hu","Dong Wang","Xuelong Li","Feiping Nie","Qi Wang"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c716bb52e5e46a2dbaebc46fda1517d6","permalink":"/publication/listen-to-the-image/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/listen-to-the-image/","section":"publication","summary":"","tags":null,"title":"Listen to the Image","type":"publication"},{"authors":["Di Hu","Xiaoqiang Lu","Xuelong Li"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"09affd8c2ded11a4005e40db4e1b960d","permalink":"/publication/multimodal-learning-via-exploring-deep-semantic-similarity/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/multimodal-learning-via-exploring-deep-semantic-similarity/","section":"publication","summary":"","tags":null,"title":"Multimodal Learning via Exploring Deep Semantic Similarity","type":"publication"},{"authors":["Rui Qian","Di Hu","Heinrich Dinkel","Mengyue Wu","Ning Xu","Weiyao Lin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"88c9d48496c44a5980763aa946676e9e","permalink":"/publication/multiple-sound-sources-localization-from-coarse-to-fine/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/multiple-sound-sources-localization-from-coarse-to-fine/","section":"publication","summary":"","tags":null,"title":"Multiple Sound Sources Localization from Coarse to Fine","type":"publication"},{"authors":["Ziyun Li","Xinshao Wang","Haojin Yang","Di Hu","Neil M Robertson","David A Clifton","Christoph Meinel"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a48ea4ca10463e6ef980903ef312977d","permalink":"/publication/not-all-knowledge-is-created-equal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/not-all-knowledge-is-created-equal/","section":"publication","summary":"","tags":null,"title":"Not All Knowledge Is Created Equal","type":"publication"},{"authors":["Konrad Heidler","Lichao Mou","Di Hu*","Pu Jin","Guangyao Li","Chuang Gan","Ji-Rong Wen","Xiao Xiang Zhu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"36c9fd21445495f69bad705471393094","permalink":"/publication/self-supervised-audiovisual-representation-learning-for-remote-sensing-data/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/self-supervised-audiovisual-representation-learning-for-remote-sensing-data/","section":"publication","summary":"","tags":null,"title":"Self-supervised Audiovisual Representation Learning for Remote Sensing Data","type":"publication"},{"authors":["Di Hu","Zheng Wang","Feiping Nie","Rong Wang","Xuelong Li"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ac1ac86aa9c1772d446b7594a05d9100","permalink":"/publication/self-supervised-learning-for-heterogeneous-audiovisual-scene-analysis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/self-supervised-learning-for-heterogeneous-audiovisual-scene-analysis/","section":"publication","summary":"","tags":null,"title":"Self-supervised Learning for Heterogeneous Audiovisual Scene Analysis","type":"publication"},{"authors":["Dongzhan Zhou","Xinchi Zhou","Di Hu*","Hang Zhou","Lei Bai","Ziwei Liu","Wanli Ouyang"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3f2c9d5779b3cec3c9b69a845335b218","permalink":"/publication/sepfusion_-finding-optimal-fusion-structures-for-visual-sound-separation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/sepfusion_-finding-optimal-fusion-structures-for-visual-sound-separation/","section":"publication","summary":"","tags":null,"title":"SepFusion: Finding Optimal Fusion Structures for Visual Sound Separation","type":"publication"},{"authors":["Di Hu","Xuelong Li","Xiaoqiang Lu"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d6704b0eb55495bb979be6fcbb8243ae","permalink":"/publication/temporal-multimodal-learning-in-audiovisual-speech-recognition/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/temporal-multimodal-learning-in-audiovisual-speech-recognition/","section":"publication","summary":"","tags":null,"title":"Temporal Multimodal Learning in Audiovisual Speech Recognition","type":"publication"},{"authors":["Dong Wang","Di Hu*","Xingjian Li","Dejing Dou"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"807bb234ac2724175550dbdf52f64d08","permalink":"/publication/temporal-relational-modeling-with-self-supervision-for-action-segmentation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/temporal-relational-modeling-with-self-supervision-for-action-segmentation/","section":"publication","summary":"","tags":null,"title":"Temporal Relational Modeling with Self-Supervision for Action Segmentation","type":"publication"},{"authors":["Xingjian Li","Di Hu","Xuhong Li","Haoyi Xiong","Zhi Ye","Zhipeng Wang","Chengzhong Xu","Dejing Dou"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5b40a464bbfccb601c6d4c37e85cf81e","permalink":"/publication/towards-accurate-knowledge-transfer-via-target-awareness-representation-disentanglement/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/towards-accurate-knowledge-transfer-via-target-awareness-representation-disentanglement/","section":"publication","summary":"","tags":null,"title":"Towards Accurate Knowledge Transfer via Target-awareness Representation Disentanglement","type":"publication"},{"authors":["Zechen Bai","Zhigang Wang","Jian Wang","Di Hu*","Errui Ding*"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9905f139a565b4f5eabfc5902965f851","permalink":"/publication/unsupervised-multi-source-domain-adaptation-for-person-re-identification/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/unsupervised-multi-source-domain-adaptation-for-person-re-identification/","section":"publication","summary":"","tags":null,"title":"Unsupervised Multi-Source Domain Adaptation for Person Re-Identification","type":"publication"},{"authors":["Xian Liu","Rui Qian","Hang Zhou","Di Hu","Weiyao Lin","Ziwei Liu","Bolei Zhou","Xiaowei Zhou"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ca462fd19e2017e2ecb2b26a145ef250","permalink":"/publication/visual-sound-localization-in-the-wild-by-cross-modal-interference-erasing/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/visual-sound-localization-in-the-wild-by-cross-modal-interference-erasing/","section":"publication","summary":"","tags":null,"title":"Visual Sound Localization in-the-Wild by Cross-Modal Interference Erasing","type":"publication"}]