---
title: Sensory Substitution for the Blind
summary: GeWu Lab is working on how to develop more effectively cross-modal encoding scheme for the disable people with AI technique and this project is trying to help more blind-friends in China Mainland.

# Optional external URL for project (replaces project detail page).
# external_link: http://example.org
weight: 5
image:
  caption:
  focal_point: Smart
---
GeWu Lab is working on how to develop more effectively cross-modal encoding scheme for the disable people with AI technique. Recently, we have published one paper <Listen to the Image> on the IEEE Computer Vision and Pattern Recognition (CVPR) conference, which employed machine model to automatically evaluate the quality of different V-to-A encoding schemes. This project still has more interesting problems should be explored, e.g. the automatically designed V-to-A encoding Scheme. Not only that, we finally hope we can deploy the devices in China Mainland to help more blind-friends, that is what GeWu Lab really expects! Great thanks for the help from the inventor of the [vOICe](https://www.seeingwithsound.com/), Peter Meijer. Recently, we translated the manual of vOICe into [Chinese](https://www.seeingwithsound.cn/manual/The_vOICe_%E5%9F%B9%E8%AE%AD%E6%89%8B%E5%86%8C_cn.htm) for the training of native Chinese.